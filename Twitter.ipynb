{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Run the following command:\r\n",
    "\r\n",
    "pip install -r requirements.txt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "import re\r\n",
    "import tweepy\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.models import Sequential,load_model\r\n",
    "#from tensorflow.python.keras.utils import _____\r\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "## Importing all the relevant libraries"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "from dotenv import load_dotenv, dotenv_values\r\n",
    "secrets = dotenv_values(\".env\")\r\n",
    "\r\n",
    "#Imports the credentials for Twitter\r\n",
    "\r\n",
    "consumerKey = secrets[\"consumerKey\"]\r\n",
    "consumerSecret = secrets[\"consumerSecret\"]\r\n",
    "accessToken = secrets[\"accessToken\"]\r\n",
    "accessSecret = secrets[\"accessSecret\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "authenticate = tweepy.OAuthHandler(consumerKey,consumerSecret)\r\n",
    "authenticate.set_access_token(accessToken,accessSecret)\r\n",
    "\r\n",
    "api = tweepy.API(authenticate,wait_on_rate_limit= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "mention = api.mentions_timeline()\r\n",
    "print(mention)\r\n",
    "\r\n",
    "for tweets in mention:\r\n",
    "  print(str(tweets.id)+'-'+tweets.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "dftweet = pd.DataFrame(['I hate him'],columns = [\"Column2\"])\r\n",
    "dftweet.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Column2\n",
       "0  I hate him"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate him</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "#clean tweets\r\n",
    "def cleanTxt(text):\r\n",
    "  text =re.sub(r'@[A-Za-z0-9]+','',text) #remove @\r\n",
    "  text = re.sub(r'#','',text)# remove #\r\n",
    "  text = re.sub(r'RT[\\s]+','',text)# remove RT\r\n",
    "  text = re.sub(r'https?:\\/\\/\\S+','',text)#remove hyperlink\r\n",
    "\r\n",
    "  return text\r\n",
    "\r\n",
    "dftweet['Column2']= dftweet['Column2'].apply(cleanTxt)\r\n",
    "print(dftweet)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Column2\n",
      "0  I hate him\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "df = pd.read_csv('combined.csv')\r\n",
    "df = pd.read_csv('new.csv')\r\n",
    "df.Column1 =df.Column1.astype(str)\r\n",
    "df.Column2 =df.Column2.astype(str)\r\n",
    "df['Column1']= df['Column1'].apply(cleanTxt)\r\n",
    "df.head()\r\n",
    "#df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             Column1  Column2\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "indexNames = df[ df['Column2'] == 'nan' ].index\r\n",
    "df.drop(indexNames , inplace=True)\r\n",
    "df['Column2'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: Column2, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "\r\n",
    "tokenizer = Tokenizer(num_words=5000,split =\" \")\r\n",
    "tokenizer.fit_on_texts(df['Column1'].values)\r\n",
    "\r\n",
    "df_x = tokenizer.texts_to_sequences(df['Column1'].values)\r\n",
    "df_x = pad_sequences(df_x)\r\n",
    "print(df_x[:5])\r\n",
    "\r\n",
    "tokenizer.fit_on_texts(dftweet['Column2'].values)\r\n",
    "x_tweet = tokenizer.texts_to_sequences(dftweet['Column2'].values)\r\n",
    "x_tweet = pad_sequences(x_tweet)\r\n",
    "\r\n",
    "print(df_x.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1  138    2  678]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1   39  100   59    7   14  493    4   14 3495  552   31   59   60\n",
      "   127  147   75 1479    3   21 1254]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0   16 3059    6\n",
      "  1148    4  285    1    2  494  437]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1   23  164    7  664   26    5 4157    1   58   46\n",
      "     8   12   21   71   29    5 3496]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    1   23    7 1064]]\n",
      "(16000, 63)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "df_y = pd.get_dummies(df['Column2']).values\r\n",
    "[print(df['Column2'][i],df_y[i]) for i in range(101,135)]\r\n",
    "print(df_x.shape)\r\n",
    "print(df_y.shape)\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_x,df_y,test_size = 0.2,random_state = 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "love [0 0 0 1 0 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "fear [0 1 0 0 0 0]\n",
      "fear [0 1 0 0 0 0]\n",
      "fear [0 1 0 0 0 0]\n",
      "sadness [0 0 0 0 1 0]\n",
      "love [0 0 0 1 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "love [0 0 0 1 0 0]\n",
      "fear [0 1 0 0 0 0]\n",
      "surprise [0 0 0 0 0 1]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "joy [0 0 1 0 0 0]\n",
      "anger [1 0 0 0 0 0]\n",
      "(16000, 63)\n",
      "(16000, 6)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(5000,256,input_length=df_x.shape[1]))\r\n",
    "#model.add(Dense(4, activation='softmax'))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(LSTM(256,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(LSTM(256,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(Dense(6,activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 63, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 63, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 63, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 2,332,166\n",
      "Trainable params: 2,332,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "model.fit(x_train, y_train,epochs=10,batch_size =32,verbose=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "400/400 - 421s - loss: 1.1831 - accuracy: 0.5562\n",
      "Epoch 2/10\n",
      "400/400 - 408s - loss: 0.3216 - accuracy: 0.8905\n",
      "Epoch 3/10\n",
      "400/400 - 396s - loss: 0.1500 - accuracy: 0.9432\n",
      "Epoch 4/10\n",
      "400/400 - 394s - loss: 0.1036 - accuracy: 0.9566\n",
      "Epoch 5/10\n",
      "400/400 - 399s - loss: 0.0884 - accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "400/400 - 394s - loss: 0.0718 - accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "400/400 - 392s - loss: 0.0632 - accuracy: 0.9766\n",
      "Epoch 8/10\n",
      "400/400 - 394s - loss: 0.0607 - accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "400/400 - 392s - loss: 0.0510 - accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "400/400 - 395s - loss: 0.0434 - accuracy: 0.9834\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21f9d3529d0>"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "model.save('sentiment')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment\\assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "# LOOKS AT THE CONTENT OF THE MENTIONED TWEET\r\n",
    "#tweets = api.mentions_timeline(tweet_mode='extended')\r\n",
    "#a = tweets[3].in_reply_to_status_id_str\r\n",
    "#tweet_a = api.get_status(id=a)\r\n",
    "#print(tweet_a.text)\r\n",
    "def check (i):\r\n",
    "    print(i)\r\n",
    "    print(np.max(i))\r\n",
    "    a = np.where(i == np.max(i))\r\n",
    "    a = a[0][0]\r\n",
    "    if ( a == 0):\r\n",
    "        return('Anger')\r\n",
    "    elif (a == 1):\r\n",
    "        return('Fear')\r\n",
    "    elif (a ==2):\r\n",
    "        return('Joy')\r\n",
    "    elif (a ==3):\r\n",
    "        return('Love')\r\n",
    "    elif (a ==4):\r\n",
    "        return('Sadness')   \r\n",
    "    else:\r\n",
    "        return('Surprised')\r\n",
    "\r\n",
    "predictions = model.predict(x_tweet)\r\n",
    "print (dftweet.Column2[0])\r\n",
    "#print ( (np.where(predictions[0] == np.max(predictions[0])))[0][0])\r\n",
    "#[print(df['Column1'][i],predictions[i],y_test[i]) for i in range (0,1)]\r\n",
    "#print(check(y_test[0]))\r\n",
    "print(check(predictions[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I hate him\n",
      "[0.14295103 0.14247619 0.14279318 0.14279813 0.14272663 0.14315179\n",
      " 0.14310299]\n",
      "0.14315179\n",
      "Sadness\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "223c27acd2f0d30991757af3704a37d958d615953cddcb1d78c6a06176f530c7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}