{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Run the following command:\r\n",
    "\r\n",
    "pip install -r requirements.txt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import re\r\n",
    "import tweepy\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.models import Sequential,load_model\r\n",
    "#from tensorflow.python.keras.utils import _____\r\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "## Importing all the relevant libraries"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from dotenv import load_dotenv, dotenv_values\r\n",
    "secrets = dotenv_values(\".env\")\r\n",
    "\r\n",
    "#Imports the credentials for Twitter\r\n",
    "\r\n",
    "consumerKey = secrets[\"consumerKey\"]\r\n",
    "consumerSecret = secrets[\"consumerSecret\"]\r\n",
    "accessToken = secrets[\"accessToken\"]\r\n",
    "accessSecret = secrets[\"accessSecret\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "authenticate = tweepy.OAuthHandler(consumerKey,consumerSecret)\r\n",
    "authenticate.set_access_token(accessToken,accessSecret)\r\n",
    "\r\n",
    "api = tweepy.API(authenticate,wait_on_rate_limit= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "mention = api.mentions_timeline()\r\n",
    "print(mention)\r\n",
    "\r\n",
    "for tweets in mention:\r\n",
    "  print(str(tweets.id)+'-'+tweets.text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dftweet = pd.DataFrame(['Circle K is dead to me. I hate your new slushie machine. #irate #livid'],columns = [\"Column2\"])\r\n",
    "dftweet.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             Column2\n",
       "0  Circle K is dead to me. I hate your new slushi..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Circle K is dead to me. I hate your new slushi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#clean tweets\r\n",
    "def cleanTxt(text):\r\n",
    "  text =re.sub(r'@[A-Za-z0-9]+','',text) #remove @\r\n",
    "  text = re.sub(r'#','',text)# remove #\r\n",
    "  text = re.sub(r'RT[\\s]+','',text)# remove RT\r\n",
    "  text = re.sub(r'https?:\\/\\/\\S+','',text)#remove hyperlink\r\n",
    "\r\n",
    "  return text\r\n",
    "\r\n",
    "dftweet['Column2']= dftweet['Column2'].apply(cleanTxt)\r\n",
    "print(dftweet)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                             Column2\n",
      "0  Circle K is dead to me. I hate your new slushi...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df = pd.read_csv('combined.csv')\r\n",
    "df['Column2']= df['Column2'].apply(cleanTxt)\r\n",
    "df.head()\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3613, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    " \r\n",
    "tokenizer = Tokenizer(num_words=5000,split =\" \")\r\n",
    "tokenizer.fit_on_texts(df['Column2'].values)\r\n",
    "\r\n",
    "df_x = tokenizer.texts_to_sequences(df['Column2'].values)\r\n",
    "df_x = pad_sequences(df_x)\r\n",
    "print(df_x[:5])\r\n",
    "\r\n",
    "tokenizer.fit_on_texts(dftweet['Column2'].values)\r\n",
    "x_tweet = tokenizer.texts_to_sequences(dftweet['Column2'].values)\r\n",
    "x_tweet = pad_sequences(x_tweet)\r\n",
    "\r\n",
    "print(df_x.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    0    0    0    0    0    0    0    3   45  335  429 4506 4507\n",
      "  1803 4508   23 4509 1804  924 4510 4511 4512    5  379 2484  162  831\n",
      "    59    6   10   98]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0  134    4 4513   13\n",
      "   430    9 1038  649]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    3  102   26    3  111 1805\n",
      "   169  154 2485 1435]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    3   43   18  182  114  650   36  323\n",
      "     2    3  231  564]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    3\n",
      "    90   10 2486  187]]\n",
      "(3613, 32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "df_y = pd.get_dummies(df['Column3']).values\r\n",
    "[print(df['Column3'][i],df_y[i]) for i in range(0,3)]\r\n",
    "print(df_x.shape)\r\n",
    "print(df_y.shape)\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_x,df_y,test_size = 0.2,random_state = 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sadness [0 0 0 1]\n",
      "joy [0 0 1 0]\n",
      "fear [0 1 0 0]\n",
      "(3613, 32)\n",
      "(3613, 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(5000,256,input_length=df_x.shape[1]))\r\n",
    "#model.add(Dense(4, activation='softmax'))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(LSTM(256,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(LSTM(256,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(Dense(4,activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 2,331,652\n",
      "Trainable params: 2,331,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "model.fit(x_train, y_train,epochs=10,batch_size = 32,verbose=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "91/91 - 35s - loss: 0.1715 - accuracy: 0.9484\n",
      "Epoch 2/10\n",
      "91/91 - 33s - loss: 0.1002 - accuracy: 0.9699\n",
      "Epoch 3/10\n",
      "91/91 - 34s - loss: 0.0705 - accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "91/91 - 32s - loss: 0.0613 - accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "91/91 - 32s - loss: 0.0477 - accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "91/91 - 31s - loss: 0.0498 - accuracy: 0.9844\n",
      "Epoch 7/10\n",
      "91/91 - 29s - loss: 0.0429 - accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "91/91 - 34s - loss: 0.0414 - accuracy: 0.9827\n",
      "Epoch 9/10\n",
      "91/91 - 34s - loss: 0.0345 - accuracy: 0.9851\n",
      "Epoch 10/10\n",
      "91/91 - 29s - loss: 0.0392 - accuracy: 0.9851\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21f83075af0>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model.save('sentiment')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment\\assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# LOOKS AT THE CONTENT OF THE MENTIONED TWEET\r\n",
    "#tweets = api.mentions_timeline(tweet_mode='extended')\r\n",
    "#a = tweets[3].in_reply_to_status_id_str\r\n",
    "#tweet_a = api.get_status(id=a)\r\n",
    "#print(tweet_a.text)\r\n",
    "def check (i):\r\n",
    "    print(i)\r\n",
    "    print(np.max(i))\r\n",
    "    a = np.where(i == np.max(i))\r\n",
    "    a = a[0][0]\r\n",
    "    if ( a == 0):\r\n",
    "        return('Anger')\r\n",
    "    elif (a == 1):\r\n",
    "        return('Fear')\r\n",
    "    elif (a ==2):\r\n",
    "        return('Joy')\r\n",
    "    else:\r\n",
    "        return('Sadness')\r\n",
    "\r\n",
    "predictions = model.predict(x_tweet)\r\n",
    "[print(df['Column2'][i],predictions[i],y_test[i]) for i in range (0,1)]\r\n",
    "print(check(y_test[0]))\r\n",
    "print(check(predictions[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I can literally eat creamy pesto pasta topped with grilled chicken, sun dried tomatoes, asparagus and pine nuts every single day of my life [2.7524629e-03 3.2543772e-04 9.9663228e-01 2.8989892e-04] [0 1 0 0]\n",
      "[0 1 0 0]\n",
      "1\n",
      "Fear\n",
      "[2.7524629e-03 3.2543772e-04 9.9663228e-01 2.8989892e-04]\n",
      "0.9966323\n",
      "Joy\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "223c27acd2f0d30991757af3704a37d958d615953cddcb1d78c6a06176f530c7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}