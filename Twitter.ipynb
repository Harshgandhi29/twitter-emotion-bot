{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Run the following command:\r\n",
    "\r\n",
    "pip install -r requirements.txt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\r\n",
    "import tweepy\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.models import Sequential,load_model\r\n",
    "#from tensorflow.python.keras.utils import _____\r\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "## Importing all the relevant libraries"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from dotenv import load_dotenv, dotenv_values\r\n",
    "secrets = dotenv_values(\".env\")\r\n",
    "\r\n",
    "#Imports the credentials for Twitter\r\n",
    "\r\n",
    "consumerKey = secrets[\"consumerKey\"]\r\n",
    "consumerSecret = secrets[\"consumerSecret\"]\r\n",
    "accessToken = secrets[\"accessToken\"]\r\n",
    "accessSecret = secrets[\"accessSecret\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "authenticate = tweepy.OAuthHandler(consumerKey,consumerSecret)\r\n",
    "authenticate.set_access_token(accessToken,accessSecret)\r\n",
    "\r\n",
    "api = tweepy.API(authenticate,wait_on_rate_limit= True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mention = api.mentions_timeline()\r\n",
    "print(mention)\r\n",
    "\r\n",
    "for tweets in mention:\r\n",
    "  print(str(tweets.id)+'-'+tweets.text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dftweet = pd.DataFrame(['I hate him'],columns = [\"Column2\"])\r\n",
    "dftweet.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#clean tweets\r\n",
    "def cleanTxt(text):\r\n",
    "  text =re.sub(r'@[A-Za-z0-9]+','',text) #remove @\r\n",
    "  text = re.sub(r'#','',text)# remove #\r\n",
    "  text = re.sub(r'RT[\\s]+','',text)# remove RT\r\n",
    "  text = re.sub(r'https?:\\/\\/\\S+','',text)#remove hyperlink\r\n",
    "\r\n",
    "  return text\r\n",
    "\r\n",
    "dftweet['Column2']= dftweet['Column2'].apply(cleanTxt)\r\n",
    "print(dftweet)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('./datasets/combined.csv')\r\n",
    "df = pd.read_csv('./datasets/new.csv')\r\n",
    "df.Column1 =df.Column1.astype(str)\r\n",
    "df.Column2 =df.Column2.astype(str)\r\n",
    "df['Column1']= df['Column1'].apply(cleanTxt)\r\n",
    "df.head()\r\n",
    "#df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "indexNames = df[ df['Column2'] == 'nan' ].index\r\n",
    "df.drop(indexNames , inplace=True)\r\n",
    "df['Column2'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "tokenizer = Tokenizer(num_words=5000,split =\" \")\r\n",
    "tokenizer.fit_on_texts(df['Column1'].values)\r\n",
    "\r\n",
    "df_x = tokenizer.texts_to_sequences(df['Column1'].values)\r\n",
    "df_x = pad_sequences(df_x)\r\n",
    "print(df_x[:5])\r\n",
    "\r\n",
    "tokenizer.fit_on_texts(dftweet['Column2'].values)\r\n",
    "x_tweet = tokenizer.texts_to_sequences(dftweet['Column2'].values)\r\n",
    "x_tweet = pad_sequences(x_tweet)\r\n",
    "\r\n",
    "print(df_x.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_y = pd.get_dummies(df['Column2']).values\r\n",
    "[print(df['Column2'][i],df_y[i]) for i in range(101,135)]\r\n",
    "print(df_x.shape)\r\n",
    "print(df_y.shape)\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(df_x,df_y,test_size = 0.2,random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential()\r\n",
    "model.add(Embedding(5000,256,input_length=df_x.shape[1]))\r\n",
    "#model.add(Dense(4, activation='softmax'))\r\n",
    "model.add(Dropout(0.3))\r\n",
    "model.add(LSTM(256,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(LSTM(256,dropout=0.3,recurrent_dropout=0.2))\r\n",
    "model.add(Dense(6,activation='softmax'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14748/440562558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2475\u001b[0m     \"\"\"\n\u001b[0;32m   2476\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2478\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(x_train, y_train,epochs=10,batch_size =32,verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('sentiment')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LOOKS AT THE CONTENT OF THE MENTIONED TWEET\r\n",
    "#tweets = api.mentions_timeline(tweet_mode='extended')\r\n",
    "#a = tweets[3].in_reply_to_status_id_str\r\n",
    "#tweet_a = api.get_status(id=a)\r\n",
    "#print(tweet_a.text)\r\n",
    "def check (i):\r\n",
    "    print(i)\r\n",
    "    print(np.max(i))\r\n",
    "    a = np.where(i == np.max(i))\r\n",
    "    a = a[0][0]\r\n",
    "    if ( a == 0):\r\n",
    "        return('Anger')\r\n",
    "    elif (a == 1):\r\n",
    "        return('Fear')\r\n",
    "    elif (a ==2):\r\n",
    "        return('Joy')\r\n",
    "    elif (a ==3):\r\n",
    "        return('Love')\r\n",
    "    elif (a ==4):\r\n",
    "        return('Sadness')   \r\n",
    "    else:\r\n",
    "        return('Surprised')\r\n",
    "\r\n",
    "predictions = model.predict(x_tweet)\r\n",
    "print (dftweet.Column2[0])\r\n",
    "#print ( (np.where(predictions[0] == np.max(predictions[0])))[0][0])\r\n",
    "#[print(df['Column1'][i],predictions[i],y_test[i]) for i in range (0,1)]\r\n",
    "#print(check(y_test[0]))\r\n",
    "print(check(predictions[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f65332f147b41578335efd8d2a3e52675cb60580caf47da42c831203f1235846"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}